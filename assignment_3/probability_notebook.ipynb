{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment 3: Probabilistic modeling\n",
    "\n",
    "In this assignment, you will work with probabilistic models known as Bayesian networks to efficiently calculate the answer to probability questions concerning discrete random variables.\n",
    "\n",
    "To help, we've provided a package called [pbnt](https://github.com/achille/pbnt) that supports the representation of Bayesian networks and automatic inference of marginal probabilities. Note that you need numpy to run pbnt.\n",
    "\n",
    "This assignment is due on T-Square by Feb 26th, 11:59PM UTC-12. Please submit your solution as probability_solution.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Warning**\n",
    "-----\n",
    "\n",
    "Due to compatibility bugs in pbnt, **this assignment requires Python 2.7 to run, which in turn requires iPython2.** So you should run this notebook using\n",
    "\n",
    "    ipython2 notebook probability_notebook.ipynb\n",
    "\n",
    "If you don't have iPython2 installed, you can download it [here](https://github.com/ipython/ipython/archive/rel-2.4.1.zip), unzip it, and install it using\n",
    "\n",
    "    python setup.py install\n",
    "\n",
    "If you don't have iPython2 installed and you don't want to have more than one version installed, you can set it up using a virtual environment (virtualenv). \n",
    "\n",
    "You can find instructions on how to set up a virtualenv under the following links:\n",
    "\n",
    "- [Windows users](http://www.tylerbutler.com/2012/05/how-to-install-python-pip-and-virtualenv-on-windows-with-powershell/) (TL;DR use PowerShell)\n",
    "- [Linux/Mac users](https://virtualenv.pypa.io/en/latest/installation.html) (TL;DR use pip if you can)\n",
    "\n",
    "Once you have virtualenv installed, you should navigate to the directory containing probability_notebook.ipynb and run the command\n",
    "\n",
    "    virtualenv .\n",
    "    \n",
    "which will create a subdirectory called \"bin\" which contains scripts to run the virtual environment. You'll then call\n",
    "\n",
    "    source bin/activate\n",
    "    \n",
    "to activate the virtualenv. You'll see that your command line now looks something like this:\n",
    "\n",
    "    (assignment_3)my-laptop:probability_assignment user_name$\n",
    "\n",
    "From here, you can install iPython2 to your local directory by running the command\n",
    "\n",
    "    pip2.7 install \"ipython [notebook]\"\n",
    "    \n",
    "and then you'll be able to open probability_notebook.ipynb using iPython2.\n",
    "\n",
    "Whenever you want to quit your virtual environment, just type\n",
    "\n",
    "    deactivate\n",
    "    \n",
    "and you can reactivate the environment later with the same command you used before. If you ever want to get rid of the virtualenv files entirely, just delete the \"bin\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The marginal probability of sprinkler=false:', 0.80102921)\n",
      "('The marginal probability of wetgrass=false | cloudy=False, rain=True:', 0.055)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Testing pbnt. Run this before anything else to get pbnt to work!\"\"\"\n",
    "import sys\n",
    "if('pbnt/combined' not in sys.path):\n",
    "    sys.path.append('pbnt/combined')\n",
    "from exampleinference import inferenceExample\n",
    "\n",
    "inferenceExample()\n",
    "# Should output:\n",
    "# ('The marginal probability of sprinkler=false:', 0.80102921)\n",
    "#('The marginal probability of wetgrass=false | cloudy=False, rain=True:', 0.055)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Part 1: Bayesian network tutorial\n",
    "-------\n",
    "35 points total\n",
    "\n",
    "To start, design a basic probabilistic model for the following system:\n",
    "\n",
    "There's a nuclear power plant in which an alarm is supposed to ring when the core temperature, indicated by a gauge, exceeds a fixed threshold. For simplicity, we assume that the temperature is represented as either high or normal. However, the alarm is sometimes faulty, and the gauge is more likely to fail when the temperature is high. Use the following Boolean variables in your implementation:\n",
    "\n",
    "- A = alarm sounds\n",
    "- F<sub>A</sub> = alarm is faulty\n",
    "- G = gauge reading (high = True, normal = False)\n",
    "- F<sub>G</sub> = gauge is faulty\n",
    "- T = actual temperature (high = True, normal = False)\n",
    "\n",
    "You will test your implementation at the end of the section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1a: Casting the net\n",
    "--\n",
    "10 points\n",
    "\n",
    "Design a Bayesian network for this system, using pbnt to represent the nodes and conditional probability arcs connecting nodes. Don't worry about the probabilities for now. Fill out the function below to create the net.\n",
    "\n",
    "The following command will create a BayesNode with 2 values, an id of 0 and the name \"alarm\":\n",
    "\n",
    "    A_node = BayesNode(0,2,name='alarm')\n",
    "\n",
    "NOTE: Do not use any special characters(like $,_,-) for the name parameter.\n",
    "\n",
    "You will use BayesNode.add\\_parent() and BayesNode.add\\_child() to connect nodes. For example, to connect the alarm and temperature nodes that you've already made (i.e. assuming that temperature affects the alarm probability):\n",
    "\n",
    "    A_node.add_parent(T_node)\n",
    "    T_node.add_child(A_node)\n",
    "    \n",
    "You can run probability\\_tests.network\\_setup\\_test() to make sure your network is set up correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "       Hint : Checkout ExampleModels.py under pbnt/combined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Node import BayesNode\n",
    "from Graph import BayesNet\n",
    "def make_power_plant_net():\n",
    "    \"\"\"Create a Bayes Net representation of the above power plant problem. \n",
    "    Use the following as the name attribute: \"alarm\",\"faulty alarm\", \"gauge\",\"faulty gauge\", \"temperature\". (for the tests to work.)\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    # TODO: finish this function\n",
    "    T_node = BayesNode(0, 2, name='temperature')\n",
    "    G_node = BayesNode(1, 2, name='gauge')\n",
    "    F_G_node = BayesNode(2, 2, name='faulty gauge')\n",
    "    F_A_node = BayesNode(3, 2, name='faulty alarm')\n",
    "    A_node = BayesNode(4, 2, name='alarm')\n",
    "    \n",
    "    T_node.add_child(G_node)\n",
    "    T_node.add_child(F_G_node)\n",
    "    \n",
    "    F_G_node.add_parent(T_node)\n",
    "    F_G_node.add_child(G_node)\n",
    "    \n",
    "    G_node.add_parent(T_node)\n",
    "    G_node.add_parent(F_G_node)\n",
    "    G_node.add_child(A_node)\n",
    "    \n",
    "    F_A_node.add_child(A_node)\n",
    "    \n",
    "    A_node.add_parent(G_node)\n",
    "    A_node.add_parent(F_A_node)\n",
    "    \n",
    "    nodes = [T_node, G_node, F_G_node, F_A_node, A_node]\n",
    "    \n",
    "    return BayesNet(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct number of nodes\n",
      "correct number of edges between nodes\n"
     ]
    }
   ],
   "source": [
    "from probability_tests import network_setup_test\n",
    "power_plant = make_power_plant_net()\n",
    "network_setup_test(power_plant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1b: Setting the probabilities\n",
    "---\n",
    "15 points\n",
    "\n",
    "Assume that the following statements about the system are true:\n",
    "\n",
    "1. The temperature gauge reads the correct temperature with 95% probability when it is not faulty and 20% probability when it is faulty. For simplicity, say that the gauge's \"true\" value corresponds with its \"hot\" reading and \"false\" with its \"normal\" reading, so the gauge would have a 95% chance of returning \"true\" when the temperature is hot and it is not faulty.\n",
    "2. The alarm is faulty 15% of the time.\n",
    "3. The temperature is hot (call this \"true\") 20% of the time.\n",
    "4. When the temperature is hot, the gauge is faulty 80% of the time. Otherwise, the gauge is faulty 5% of the time.\n",
    "5. The alarm responds correctly to the gauge 55% of the time when the alarm is faulty, and it responds correctly to the gauge 90% of the time when the alarm is not faulty. For instance, when it is faulty, the alarm sounds 55% of the time that the gauge is \"hot\" and remains silent 55% of the time that the gauge is \"normal.\"\n",
    "\n",
    "Knowing these facts, set the conditional probabilities for the necessary variables on the network you just built.\n",
    "\n",
    "Using pbnt's Distribution class: if you wanted to set the distribution for P(A) to 70% true, 30% false, you would invoke the following commands:\n",
    "\n",
    "    A_distribution = DiscreteDistribution(A_node)\n",
    "    index = A_distribution.generate_index([],[])\n",
    "    A_distribution[index] = [0.3,0.7]\n",
    "    A_node.set_dist(A_distribution)\n",
    "\n",
    "REMEMBER: USE INDEX 0 FOR FALSE IN THE CODE.\n",
    "\n",
    "If you wanted to set the distribution for P(A|G) to be\n",
    "\n",
    "|$G$|$P(A=true| G)$|\n",
    "|------|-----|\n",
    "|T| 0.75|\n",
    "|F| 0.85| \n",
    "\n",
    "you would invoke:\n",
    "\n",
    "    from numpy import zeros, float32\n",
    "    dist = zeros([G_node.size(), A_node.size()], dtype=float32)   #Note the order of G_node, A_node\n",
    "    dist[0,:] = [0.15, 0.85]\n",
    "    dist[1,:] = [0.25, 0.75]\n",
    "    A_distribution = ConditionalDiscreteDistribution(nodes=[G_node,A_node], table=dist)\n",
    "    A_node.set_dist(A_distribution)\n",
    "\n",
    "Modeling a three-variable relationship is a bit trickier. If you wanted to set the following distribution for $P(A|G,T)$ to be\n",
    "\n",
    "|$G$|$T$|$P(A=true| G, T)$|\n",
    "|--|--|:----:|\n",
    "|T|T|0.15|\n",
    "|T|F|0.6|\n",
    "|F|T|0.2|\n",
    "|F|F|0.1|\n",
    "\n",
    "you would invoke:\n",
    "\n",
    "    from numpy import zeros, float32\n",
    "    dist = zeros([G_node.size(), T_node.size(), A_node.size()], dtype=float32)\n",
    "    dist[0,0,:] = [0.9, 0.1]\n",
    "    dist[0,1,:] = [0.8, 0.2]\n",
    "    dist[1,0,:] = [0.4, 0.6]\n",
    "    dist[1,1,:] = [0.85, 0.15]\n",
    "    \n",
    "    A_distribution = ConditionalDiscreteDistribution(nodes=[G_node, T_node, A_node], table=dist)\n",
    "    A_node.set_dist(A_distribution)\n",
    "\n",
    "The key is to remember that 0 represents the index of the false probability, and 1 represents true.\n",
    "\n",
    "You can check your probability distributions with probability_tests.probability_setup_test()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from numpy import zeros, float32\n",
    "import numpy as np\n",
    "import Distribution\n",
    "from Distribution import DiscreteDistribution, ConditionalDiscreteDistribution\n",
    "def set_probability(bayes_net):\n",
    "    \"\"\"Set probability distribution for each node in the power plant system.\"\"\"\n",
    "    \n",
    "    A_node = bayes_net.get_node_by_name(\"alarm\")\n",
    "    F_A_node = bayes_net.get_node_by_name(\"faulty alarm\")\n",
    "    G_node = bayes_net.get_node_by_name(\"gauge\")\n",
    "    F_G_node = bayes_net.get_node_by_name(\"faulty gauge\")\n",
    "    T_node = bayes_net.get_node_by_name(\"temperature\")\n",
    "    nodes = [A_node, F_A_node, G_node, F_G_node, T_node]\n",
    "    # TODO: set the probability distribution for each node\n",
    "\n",
    "    #1\n",
    "    dist = np.zeros([F_G_node.size(), T_node.size(), G_node.size()], dtype=np.float32)\n",
    "    dist[0, 0, :] = [0.05, 0.95]\n",
    "    dist[0, 1, :] = [0.05, 0.95]\n",
    "    dist[1, 0, :] = [0.8, 0.2]\n",
    "    dist[1, 1, :] = [0.8, 0.2]\n",
    "    G_distribution = ConditionalDiscreteDistribution(nodes=[F_G_node, T_node, G_node], table=dist)\n",
    "    G_node.set_dist(G_distribution)\n",
    "    \n",
    "    #2\n",
    "    F_A_distribution = DiscreteDistribution(F_A_node)\n",
    "    index = F_A_distribution.generate_index([], [])\n",
    "    F_A_distribution[index] = [0.85, 0.15]\n",
    "    F_A_node.set_dist(F_A_distribution)\n",
    "    \n",
    "    #3\n",
    "    T_distribution = DiscreteDistribution(T_node)\n",
    "    index = T_distribution.generate_index([], [])\n",
    "    T_distribution[index] = [0.8, 0.2]\n",
    "    T_node.set_dist(T_distribution)\n",
    "    \n",
    "    #4\n",
    "    dist = np.zeros([T_node.size(), F_G_node.size()], dtype=np.float32)\n",
    "    dist[0, :] = [0.95, 0.05]\n",
    "    dist[1, :] = [0.2, 0.8]\n",
    "    F_G_distribution = ConditionalDiscreteDistribution(nodes=[T_node, F_G_node], table=dist)\n",
    "    F_G_node.set_dist(F_G_distribution)\n",
    "    \n",
    "    #5\n",
    "    dist = np.zeros([F_A_node.size(), G_node.size(), A_node.size()], dtype=np.float32)\n",
    "    dist[0, 0, :] = [0.1, 0.9]\n",
    "    dist[0, 1, :] = [0.1, 0.9]\n",
    "    dist[1, 0, :] = [0.45, 0.55]\n",
    "    dist[1, 1, :] = [0.45, 0.55]\n",
    "    A_distribution = ConditionalDiscreteDistribution(nodes=[F_A_node, G_node, A_node], table=dist)\n",
    "    A_node.set_dist(A_distribution)\n",
    "    \n",
    "    return bayes_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking probability distribution for Temperature node...\n",
      "correct temperature distribution size\n",
      "correct temperature distribution\n",
      "checking probability distribution for Faulty Gauge node...\n",
      "correct faulty gauge distribution size\n",
      "correct faulty gauge distribution\n",
      "checking probability distribution for Faulty Alarm node...\n",
      "correct faulty alarm distribution size\n",
      "correct faulty alarm distribution\n",
      "checking only the probability distribution size for Gauge node...\n",
      "correct gauge distribution size\n",
      "checking only the probability distribution size for Alarm node...\n",
      "correct alarm distribution size\n"
     ]
    }
   ],
   "source": [
    "set_probability(power_plant)\n",
    "from probability_tests import probability_setup_test\n",
    "probability_setup_test(power_plant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1c: Probability calculations : Perform inference\n",
    "---\n",
    "10 points\n",
    "\n",
    "To finish up, you're going to perform inference on the network to calculate the following probabilities:\n",
    "\n",
    "- the marginal probability that the alarm sounds\n",
    "- the marginal probability that the gauge shows \"hot\"\n",
    "- the probability that the temperature is actually hot, given that the alarm sounds and the alarm and gauge are both working\n",
    "\n",
    "You'll fill out the \"get_prob\" functions to calculate the probabilities.\n",
    "\n",
    "Here's an example of how to do inference for the marginal probability of the \"faulty alarm\" node being True (assuming \"bayes_net\" is your network):\n",
    "\n",
    "    F_A_node = bayes_net.get_node_by_name('faulty alarm')\n",
    "    engine = JunctionTreeEngine(bayes_net)\n",
    "    Q = engine.marginal(F_A_node)[0]\n",
    "    index = Q.generate_index([True],range(Q.nDims))\n",
    "    prob = Q[index]\n",
    "  \n",
    "To compute the conditional probability, set the evidence variables before computing the marginal as seen below (here we're computing $P(A = false | F_A = true, T = False)$):\n",
    "\n",
    "    engine.evidence[F_A_node] = True\n",
    "    engine.evidence[T_node] = False\n",
    "    Q = engine.marginal(A_node)[0]\n",
    "    index = Q.generate_index([False],range(Q.nDims))\n",
    "    prob = Q[index]\n",
    "\n",
    "If you need to sanity-check to make sure you're doing inference correctly, you can run inference on one of the probabilities that we gave you in 1b. For instance, running inference on $P(T=true)$ should return 0.19999994 (i.e. almost 20%). You can also calculate the answers by hand to double-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Inference import JunctionTreeEngine\n",
    "def get_alarm_prob(bayes_net, alarm_rings):\n",
    "    \"\"\"Calculate the marginal \n",
    "    probability of the alarm \n",
    "    ringing (T/F) in the \n",
    "    power plant system.\"\"\"\n",
    "    # TODO: finish this function\n",
    "    A_node = bayes_net.get_node_by_name('alarm')\n",
    "    engine = JunctionTreeEngine(bayes_net)\n",
    "    Q = engine.marginal(A_node)[0]\n",
    "    index = Q.generate_index([alarm_rings], range(Q.nDims))\n",
    "    alarm_prob = Q[index]\n",
    "    return alarm_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_gauge_prob(bayes_net, gauge_hot):\n",
    "    \"\"\"Calculate the marginal\n",
    "    probability of the gauge \n",
    "    showing hot (T/F) in the \n",
    "    power plant system.\"\"\"\n",
    "    # TOOD: finish this function\n",
    "    G_node = bayes_net.get_node_by_name('gauge')\n",
    "    engine = JunctionTreeEngine(bayes_net)\n",
    "    Q = engine.marginal(G_node)[0]\n",
    "    index = Q.generate_index([gauge_hot], range(Q.nDims))\n",
    "    gauge_prob = Q[index]\n",
    "    return gauge_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_temperature_prob(bayes_net,temp_hot):\n",
    "    \"\"\"Calculate the conditional probability \n",
    "    of the temperature being hot (T/F) in the\n",
    "    power plant system, given that the\n",
    "    alarm sounds and neither the gauge\n",
    "    nor alarm is faulty.\"\"\"\n",
    "    # TODO: finish this function\n",
    "    T_node = bayes_net.get_node_by_name('temperature')\n",
    "    A_node = bayes_net.get_node_by_name('alarm')\n",
    "    F_A_node = bayes_net.get_node_by_name('faulty alarm')\n",
    "    F_G_node = bayes_net.get_node_by_name('faulty gauge')\n",
    "    engine = JunctionTreeEngine(bayes_net)\n",
    "    engine.evidence[A_node] = True\n",
    "    engine.evidence[F_A_node] = False\n",
    "    engine.evidence[F_G_node] = False\n",
    "    Q = engine.marginal(T_node)[0]\n",
    "    index = Q.generate_index([temp_hot], range(Q.nDims))\n",
    "    temp_prob = Q[index]\n",
    "    return temp_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475\n",
      "0.8\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "print get_alarm_prob(power_plant,True)\n",
    "print get_gauge_prob(power_plant,True)\n",
    "print get_temperature_prob(power_plant,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Part 2: Sampling\n",
    "-----\n",
    "65 points total\n",
    "\n",
    "For the main exercise, consider the following scenario.\n",
    "\n",
    "There are three frisbee teams who play each other: the Airheads, the Buffoons, and the Clods (A, B and C for short). \n",
    "Each match is between two teams, and each team can either win, lose, or draw in a match. Each team has a fixed but \n",
    "unknown skill level, represented as an integer from 0 to 3. The outcome of each match is probabilistically proportional to the difference in skill level between the teams.\n",
    "\n",
    "Sampling is a method for ESTIMATING a probability distribution when it is prohibitively expensive (even for inference!) to completely compute the distribution. \n",
    "\n",
    "Here, we want to estimate the outcome of the matches, given prior knowledge of previous matches. Rather than using inference, we will do so by sampling the network using two [Markov Chain Monte Carlo](http://www.statistics.com/papers/LESSON1_Notes_MCMC.pdf) models: Gibbs sampling (2c) and Metropolis-Hastings (2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2a: Build the network.\n",
    "-----\n",
    "10 points\n",
    "\n",
    "For the first sub-part, consider a network with 3 teams : the Airheads, the Buffoons, and the Clods (A, B and C for short). 3 total matches are played. \n",
    "Build a Bayes Net to represent the three teams and their influences on the match outcomes. Assume the following variable conventions:\n",
    "\n",
    "| variable name | description|\n",
    "|---------|:------:|\n",
    "|A| A's skill level|\n",
    "|B | B's skill level|\n",
    "|C | C's skill level|\n",
    "|AvB | the outcome of A vs. B <br> (0 = A wins, 1 = B wins, 2 = tie)|\n",
    "|BvC | the outcome of B vs. C <br> (0 = B wins, 1 = C wins, 2 = tie)|\n",
    "|CvA | the outcome of C vs. A <br> (0 = C wins, 1 = A wins, 2 = tie)|\n",
    "\n",
    "Assume that each team has the following prior distribution of skill levels:\n",
    "\n",
    "|skill level|P(skill level)|\n",
    "|----|:----:|\n",
    "|0|0.15|\n",
    "|1|0.45|\n",
    "|2|0.30|\n",
    "|3|0.10|\n",
    "\n",
    "In addition, assume that the differences in skill levels correspond to the following probabilities of winning:\n",
    "\n",
    "| skill difference <br> (T2 - T1) | T1 wins | T2 wins| Tie |\n",
    "|------------|----------|---|:--------:|\n",
    "|0|0.10|0.10|0.80|\n",
    "|1|0.20|0.60|0.20|\n",
    "|2|0.15|0.75|0.10|\n",
    "|3|0.05|0.90|0.05|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_skill_distribution(node):\n",
    "    distribution = DiscreteDistribution(node)\n",
    "    index = distribution.generate_index([], [])\n",
    "    distribution[index] = [0.15, 0.45, 0.3, 0.1]\n",
    "    node.set_dist(distribution)\n",
    "    return node\n",
    "\n",
    "\n",
    "def set_skill_diff_distribution(node, dist_nodes):\n",
    "    dist = np.zeros([dist_node.size() for dist_node in dist_nodes], dtype=np.float32)\n",
    "    # skill diff = 0\n",
    "    dist[0, 0] = dist[1, 1] = dist[2, 2] = dist[3, 3] = [0.1, 0.1, 0.8]\n",
    "\n",
    "    # skill diff = 1\n",
    "    dist[0, 1] = dist[1, 2] = dist[2, 3] = [0.2, 0.6, 0.2]\n",
    "    dist[1, 0] = dist[2, 1] = dist[3, 2] = [0.6, 0.2, 0.2]\n",
    "\n",
    "    # skill diff = 2\n",
    "    dist[0, 2] = dist[1, 3] = [0.15, 0.75, 0.1]\n",
    "    dist[2, 0] = dist[3, 1] = [0.75, 0.15, 0.1]\n",
    "\n",
    "    # skill diff = 3\n",
    "    dist[0, 3] = [0.05, 0.9, 0.05]\n",
    "    dist[3, 0] = [0.9, 0.05, 0.05]\n",
    "    \n",
    "    distribution = ConditionalDiscreteDistribution(nodes=dist_nodes, table=dist)\n",
    "    node.set_dist(distribution)\n",
    "    return node\n",
    "\n",
    "\n",
    "def get_game_network():\n",
    "    \"\"\"Create a Bayes Net representation of the game problem.\n",
    "    Name the nodes as \"A\",\"B\",\"C\",\"AvB\",\"BvC\" and \"CvA\".  \"\"\"\n",
    "    nodes = []\n",
    "    # TODO: fill this out\n",
    "    A_node = BayesNode(0, 4, name='A')\n",
    "    B_node = BayesNode(1, 4, name='B')\n",
    "    C_node = BayesNode(2, 4, name='C')\n",
    "    AvB_node = BayesNode(3, 3, name='AvB')\n",
    "    BvC_node = BayesNode(4, 3, name='BvC')\n",
    "    CvA_node = BayesNode(5, 3, name='CvA')\n",
    "    \n",
    "    A_node.add_child(AvB_node)\n",
    "    A_node.add_child(CvA_node)\n",
    "    \n",
    "    B_node.add_child(AvB_node)\n",
    "    B_node.add_child(BvC_node)\n",
    "    \n",
    "    C_node.add_child(BvC_node)\n",
    "    C_node.add_child(CvA_node)\n",
    "    \n",
    "    AvB_node.add_parent(A_node)\n",
    "    AvB_node.add_parent(B_node)\n",
    "    \n",
    "    BvC_node.add_parent(B_node)\n",
    "    BvC_node.add_parent(C_node)\n",
    "    \n",
    "    CvA_node.add_parent(A_node)\n",
    "    CvA_node.add_parent(C_node)\n",
    "    \n",
    "    nodes = [A_node, B_node, C_node, AvB_node, BvC_node, CvA_node]\n",
    "    \n",
    "    A_node = set_skill_distribution(A_node)\n",
    "    B_node = set_skill_distribution(B_node)\n",
    "    C_node = set_skill_distribution(C_node)\n",
    "    \n",
    "    AvB_node = set_skill_diff_distribution(AvB_node, [A_node, B_node, AvB_node])\n",
    "    BvC_node = set_skill_diff_distribution(BvC_node, [B_node, C_node, BvC_node])\n",
    "    CvA_node = set_skill_diff_distribution(CvA_node, [C_node, A_node, CvA_node])\n",
    "\n",
    "    return BayesNet(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking the total number of edges and nodes in the network...\n",
      "correct number of nodes\n",
      "correct number of edges\n",
      "checking probability distribution for Team A...\n",
      "correct team distribution size\n",
      "correct team distribution\n",
      "checking probability distribution for match AvB...\n",
      "correct match distribution size\n",
      "correct match distribution\n"
     ]
    }
   ],
   "source": [
    "game_net = get_game_network()\n",
    "\n",
    "from probability_tests import games_network_test\n",
    "games_network_test(game_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2b: Calculate posterior distribution for the 3rd match.\n",
    "----\n",
    "5 points\n",
    "\n",
    "Suppose that you know the following outcome of two of the three games: A beats B and A draws with C. Calculate the posterior distribution for the outcome of the BvC match in calculate_posterior(). Use EnumerationEngine ONLY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Inference import EnumerationEngine\n",
    "\n",
    "def calculate_posterior(bayes_net):\n",
    "    \"\"\"Calculate the posterior distribution of the BvC match given that A won against B and tied C. \n",
    "    Return a list of probabilities corresponding to win, loss and tie likelihood.\"\"\"\n",
    "    posterior = [0,0,0]\n",
    "    # TODO: finish this function\n",
    "    AvB_node = bayes_net.get_node_by_name('AvB')\n",
    "    CvA_node = bayes_net.get_node_by_name('CvA')\n",
    "    BvC_node = bayes_net.get_node_by_name('BvC')\n",
    "    \n",
    "    engine = EnumerationEngine(bayes_net)\n",
    "    engine.evidence[AvB_node] = 0\n",
    "    engine.evidence[CvA_node] = 2\n",
    "    Q = engine.marginal(BvC_node)[0]\n",
    "    \n",
    "    match_results = [0, 1, 2]\n",
    "    for i, result in enumerate(match_results):\n",
    "        index = Q.generate_index([result], range(Q.nDims))\n",
    "        posterior[i] = Q[index]\n",
    "    \n",
    "    return posterior # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct posterior\n",
      "[0.25890073, 0.42796761, 0.3131316]\n"
     ]
    }
   ],
   "source": [
    "from probability_tests import posterior_test\n",
    "posterior = calculate_posterior(game_net)\n",
    "posterior_test(posterior)\n",
    "print posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2c: Gibbs sampling\n",
    "---\n",
    "15 points\n",
    "\n",
    "Implement the Gibbs sampling algorithm, which is a special case of Metropolis-Hastings. You'll do this in Gibbs_sampler(), which takes a Bayesian network and initial state value as a parameter and returns a sample state drawn from the network's distribution. In case of Gibbs, the returned state differs from the input state at at-most one variable (randomly chosen).\n",
    "\n",
    "The method should just consist of a single iteration of the algorithm. If an initial value is not given, default to a state chosen uniformly at random from the possible states.\n",
    "\n",
    "Note: DO NOT USE the given inference engines to run the sampling method, since the whole point of sampling is to calculate marginals without running inference. \n",
    "\n",
    "\n",
    "     \"YOU WILL SCORE 0 POINTS ON THIS ASSIGNMENT IF YOU USE THE GIVEN INFERENCE ENGINES FOR THIS PART!!\"\n",
    "\n",
    "\n",
    "You may find [this](http://gandalf.psych.umn.edu/users/schrater/schrater_lab/courses/AI2/gibbs.pdf) helpful in understanding the basics of Gibbs sampling over Bayesian networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hint 1: In both Metropolis-Hastings and Gibbs sampling, you'll need access to each node's probability distribution and nodes. \n",
    "You can access these by calling: \n",
    "    \n",
    "    A = bayes_net.get_node_by_name(\"A\")      \n",
    "    team_table = A.dist.table\n",
    "    AvB = bayes_net.get_node_by_name(\"AvB\")\n",
    "    match_table = AvB.dist.table\n",
    "    \n",
    "which will return the same numpy array that you provided when constructing the probability distribution.\n",
    "\n",
    "Hint 2: you'll also want to use the random package (e.g. random.randint()) for the probabilistic choices that sampling makes.\n",
    "\n",
    "Hint 3: in order to count the sample states later on, you'll want to make sure the sample that you return is hashable. One way to do this is by returning the sample as a tuple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_random_state(nodes):\n",
    "    return [np.random.choice(xrange(node.numValues)) for node in nodes]\n",
    "\n",
    "\n",
    "def get_initial_state(nodes, initial_state):\n",
    "    # if initial_state is not defined, get random initial\n",
    "    if initial_state is None or len(initial_state) != len(nodes):\n",
    "        return get_random_state(nodes)\n",
    "    return initial_state\n",
    "\n",
    "\n",
    "def get_markov_blanket_probability(nodes, node, state):\n",
    "    # markov blanket includes its parent, children, and the other parents\n",
    "    p = get_probability(nodes, node, state)\n",
    "    for child in node.children:\n",
    "        p = p * get_probability(nodes, child, state)\n",
    "    return p\n",
    "\n",
    "\n",
    "def get_probability(nodes, node, state):\n",
    "    dist = node.dist.table\n",
    "    # has parents means node is match\n",
    "    if len(node.parents) > 0:\n",
    "        values = []\n",
    "        for name in [node.name[0], node.name[2]]:\n",
    "            for parent in node.parents:\n",
    "                if name == parent.name:\n",
    "                    value = state[nodes.index(parent)]\n",
    "                    values.append(value)\n",
    "        # find the probabilities given the state values\n",
    "        dist = dist[values[0], values[1]]\n",
    "    # return the probability given the node value\n",
    "    p = dist[state[nodes.index(node)]]\n",
    "    return p\n",
    "\n",
    "\n",
    "def Gibbs_sampler(bayes_net, initial_state, evidence_map = {}):\n",
    "    \"\"\"Complete a single iteration of the Gibbs sampling algorithm \n",
    "    given a Bayesian network and an initial state value. \n",
    "    \n",
    "    initial_state is a list of length 6 where: \n",
    "    index 0-2: represent skills of teams A,B,C (values lie in [0,3] inclusive)\n",
    "    index 3-5: represent results of matches AvB, BvC, CvA (values lie in [0,2] inclusive)\n",
    "    \n",
    "    Returns the new state sampled from the probability distribution as a tuple of length 6.\n",
    "    Return the sample as a tuple.    \n",
    "    \"\"\"\n",
    "    nodes = list(bayes_net.nodes)\n",
    "    initial_state = get_initial_state(nodes, initial_state)\n",
    "    \n",
    "    # get random node to change\n",
    "    node = None\n",
    "    while node is None or node in evidence_map:\n",
    "        node = nodes[np.random.randint(len(nodes))]\n",
    "    \n",
    "    sample = list(initial_state)\n",
    "    index = nodes.index(node)\n",
    "    values = xrange(node.numValues)\n",
    "    \n",
    "    # get conditional probabilities distribution\n",
    "    p_list = []\n",
    "    for value in values:\n",
    "        sample[index] = value\n",
    "        p_list.append(get_markov_blanket_probability(nodes, node, sample))\n",
    "    \n",
    "    # normalize p_list\n",
    "    p_list = np.array(p_list) / np.sum(p_list)\n",
    "    \n",
    "    # sample based on conditional probabilities\n",
    "    value = np.random.choice(values, p=p_list)\n",
    "    sample[index] = value\n",
    "\n",
    "    return tuple(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# arbitrary initial state for the game system\n",
    "initial_state = [0,0,0,0,0,0]\n",
    "sample = Gibbs_sampler(game_net, initial_state)\n",
    "print sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2d: Metropolis-Hastings sampling\n",
    "---\n",
    "15 points\n",
    "\n",
    "Now you will implement the Metropolis-Hastings algorithm, which is another method for estimating a probability distribution.\n",
    "The general idea of MH is to build an approximation of a latent probability distribution by repeatedly generating a \"candidate\" value for each random variable in the system, and then probabilistically accepting or rejecting the candidate value based on an underlying acceptance function. Unlike Gibbs, in case of MH, the returned state can differ from the initial state at more than one variable.\n",
    "This [cheat sheet](http://www.mit.edu/~ilkery/papers/MetropolisHastingsSampling.pdf) provides a nice intro.\n",
    "\n",
    "This method method should just perform a single iteration of the algorithm. If an initial value is not given, default to a state chosen uniformly at random from the possible states. \n",
    "\n",
    "Note: DO NOT USE the given inference engines to run the sampling method, since the whole point of sampling is to calculate marginals without running inference. \n",
    "\n",
    "\n",
    "     \"YOU WILL SCORE 0 POINTS IF YOU USE THE GIVEN INFERENCE ENGINES, OR ANY OTHER SAMPLING METHOD!!\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MH_sampler(bayes_net, initial_state, evidence_map = {}):\n",
    "    \"\"\"Complete a single iteration of the MH sampling algorithm given a Bayesian network and an initial state value. \n",
    "    initial_state is a list of length 6 where: \n",
    "    index 0-2: represent skills of teams A,B,C (values lie in [0,3] inclusive)\n",
    "    index 3-5: represent results of matches AvB, BvC, CvA (values lie in [0,2] inclusive)\n",
    "    \n",
    "    Returns the new state sampled from the probability distribution as a tuple of length 6. \n",
    "    \"\"\"\n",
    "    nodes = list(bayes_net.nodes)\n",
    "    initial_state = get_initial_state(nodes, initial_state)\n",
    "    \n",
    "    sample = list(initial_state)\n",
    "    candidate = list(initial_state)\n",
    "    \n",
    "    filtered_nodes = [node for node in nodes if node not in evidence_map]\n",
    "\n",
    "    # propose a candidate\n",
    "    for node in filtered_nodes:\n",
    "        index = nodes.index(node)\n",
    "        value = np.random.choice(node.numValues)\n",
    "        candidate[index] = value\n",
    "    \n",
    "    # get acceptance probability\n",
    "    current_probability = 1.\n",
    "    candidate_probability = 1.\n",
    "    for node in nodes:\n",
    "        current_probability *= get_probability(nodes, node, initial_state)\n",
    "        candidate_probability *= get_probability(nodes, node, candidate)\n",
    "    \n",
    "    if candidate_probability > current_probability:\n",
    "        # If probability of new state is greater than that of the old state, you accept the candidate.\n",
    "        sample = candidate\n",
    "    else:\n",
    "        # Else, you accept/reject the candidate by randomly choosing a value between 0 and 1 (excluding 0 and 1).\n",
    "        alpha = candidate_probability / current_probability\n",
    "        if alpha > np.random.uniform(0, 1):\n",
    "            sample = candidate\n",
    "    \n",
    "    return tuple(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 0, 0, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# arbitrary initial state for the game system\n",
    "initial_state = [0,0,0,0,0,0] \n",
    "sample = MH_sampler(game_net, initial_state)\n",
    "print sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2e: Comparing sampling methods\n",
    "----\n",
    "20 points\n",
    "\n",
    "Now we are ready for the moment of truth.\n",
    "\n",
    "Given the same outcomes as in 2b, A beats B and A draws with C, you should now estimate the likelihood of different outcomes for the third match by running Gibbs sampling until it converges to a stationary distribution. \n",
    "We'll say that the sampler has converged when, for \"N\" successive iterations, the difference in expected outcome for the 3rd match differs from the previous estimated outcome by less than \"delta\". N is a positive integer. delta goes from (0,1). For the most stationary convergence, delta should be very small. N could typically take values like 10,20,...,100 or even more.\n",
    "\n",
    "Measure how many iterations it takes for Gibbs and MH to converge to a stationary distribution over the posterior. See for yourself how close (or not) this stable distribution is to what the Inference Engine returned in 2b. And if not, try tuning those parameters(N and delta). (You might find the concept of \"burn-in\" period useful). \n",
    "\n",
    "For the purpose of this assignment, we'll say that the sampler has converged when, for 10 successive iterations, the difference in expected outcome for the third match differs from the previous estimated outcome by less than .001 (0.1%).\n",
    "\n",
    "Repeat this experiment for Metropolis-Hastings sampling.\n",
    "\n",
    "Which algorithm converges more quickly? By approximately what factor? For instance, if Metropolis-Hastings takes twice as many iterations to converge as Gibbs sampling, you'd say that it converged faster by a factor of 2. Fill in sampling_question() to answer both parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_posterior(sample_count):\n",
    "    return np.array(sample_count, dtype=np.float32) / np.sum(sample_count)\n",
    "\n",
    "\n",
    "def is_accepted(current_posterior, prev_posterior, delta):\n",
    "    if prev_posterior is None:\n",
    "        return False\n",
    "    current_posterior = np.array(current_posterior)\n",
    "    prev_posterior = np.array(prev_posterior)\n",
    "    diff = np.array(np.abs(current_posterior - prev_posterior))\n",
    "    return np.any(current_posterior != prev_posterior) and np.all(diff < delta)\n",
    "\n",
    "\n",
    "def compare_sampling(bayes_net, initial_state, delta):\n",
    "    \"\"\"Compare Gibbs and Metropolis-Hastings sampling by calculating how long it takes for each method to converge.\"\"\"    \n",
    "    Gibbs_count = 0\n",
    "    MH_count = 0\n",
    "    MH_rejection_count = 0\n",
    "    Gibbs_convergence = [0,0,0] # posterior distribution of the BvC match as produced by Gibbs \n",
    "    MH_convergence = [0,0,0] # posterior distribution of the BvC match as produced by MH\n",
    "    # TODO: finish this function\n",
    "    \n",
    "    N = 100000\n",
    "    BURN_IN = 10000\n",
    "    CONSECUTIVE_THRESHOLD = 10\n",
    "    nodes = list(bayes_net.nodes)\n",
    "    AvB = bayes_net.get_node_by_name('AvB')\n",
    "    BvC = bayes_net.get_node_by_name('BvC')\n",
    "    CvA = bayes_net.get_node_by_name('CvA')\n",
    "    \n",
    "    BvC_index = nodes.index(BvC)\n",
    "    evidence_map = { AvB: 0, CvA: 2 }\n",
    "    \n",
    "    initial_state = get_initial_state(nodes, initial_state)\n",
    "    \n",
    "    current_state = list(initial_state)\n",
    "    for node, value in evidence_map.iteritems():\n",
    "        current_state[nodes.index(node)] = value\n",
    "    \n",
    "    sample_count = [0, 0, 0]\n",
    "    prev_posterior = None\n",
    "    consecutive_iteration = 0\n",
    "    for Gibbs_count in xrange(N):\n",
    "        next_state = Gibbs_sampler(bayes_net, current_state, evidence_map)\n",
    "        current_state = next_state\n",
    "        sample_count[next_state[BvC_index]] += 1\n",
    "        \n",
    "        if Gibbs_count < BURN_IN:\n",
    "            continue\n",
    "        \n",
    "        Gibbs_convergence = get_posterior(sample_count)\n",
    "        \n",
    "        if is_accepted(Gibbs_convergence, prev_posterior, delta):\n",
    "            consecutive_iteration += 1\n",
    "        else:\n",
    "            consecutive_iteration = 0\n",
    "        prev_posterior = Gibbs_convergence\n",
    "        \n",
    "        if consecutive_iteration >= CONSECUTIVE_THRESHOLD:\n",
    "            break\n",
    "    \n",
    "    current_state = list(initial_state)\n",
    "    for node, value in evidence_map.iteritems():\n",
    "        current_state[nodes.index(node)] = value\n",
    "    \n",
    "    sample_count = [0, 0, 0]\n",
    "    prev_posterior = None\n",
    "    consecutive_iteration = 0\n",
    "    for MH_count in xrange(N):\n",
    "        next_state = MH_sampler(bayes_net, current_state, evidence_map)\n",
    "        \n",
    "        if np.all(current_state == next_state):\n",
    "            MH_rejection_count += 1\n",
    "            \n",
    "        current_state = next_state\n",
    "        sample_count[next_state[BvC_index]] += 1\n",
    "        \n",
    "        if MH_count < BURN_IN:\n",
    "            continue\n",
    "        \n",
    "        MH_convergence = get_posterior(sample_count)\n",
    "        \n",
    "        if is_accepted(MH_convergence, prev_posterior, delta):\n",
    "            consecutive_iteration += 1\n",
    "        else:\n",
    "            consecutive_iteration = 0\n",
    "        prev_posterior = MH_convergence\n",
    "        \n",
    "        if consecutive_iteration >= CONSECUTIVE_THRESHOLD:\n",
    "            break\n",
    "    \n",
    "    return list(Gibbs_convergence), list(MH_convergence), Gibbs_count, MH_count, MH_rejection_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.24962541, 0.41614226, 0.33423233],\n",
       " [0.26151234, 0.42123663, 0.31725103],\n",
       " 10010,\n",
       " 10010,\n",
       " 7968)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = [0,0,0,0,0,0]\n",
    "delta = 0.001\n",
    "compare_sampling(game_net,initial_state, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sampling_question():\n",
    "    \"\"\"Question about sampling performance.\"\"\"\n",
    "    # TODO: assign value to choice and factor\n",
    "    choice = 0\n",
    "    options = ['Gibbs','Metropolis-Hastings']\n",
    "    factor = 1\n",
    "    return options[choice], factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And we are done!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}